{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2023-03-13T16:21:33.407612Z",
     "iopub.status.busy": "2023-03-13T16:21:33.407099Z",
     "iopub.status.idle": "2023-03-13T16:21:45.092249Z",
     "shell.execute_reply": "2023-03-13T16:21:45.090511Z",
     "shell.execute_reply.started": "2023-03-13T16:21:33.407567Z"
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in /opt/conda/lib/python3.7/site-packages (0.0.27)\n",
      "Requirement already satisfied: openai in /opt/conda/lib/python3.7/site-packages (0.27.2)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from langchain) (1.21.6)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from langchain) (2.28.2)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.7/site-packages (from langchain) (6.0)\n",
      "Requirement already satisfied: sqlalchemy in /opt/conda/lib/python3.7/site-packages (from langchain) (1.4.46)\n",
      "Requirement already satisfied: pydantic in /opt/conda/lib/python3.7/site-packages (from langchain) (1.10.4)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.7/site-packages (from openai) (3.8.3)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from openai) (4.64.1)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from openai) (4.4.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->langchain) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->langchain) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->langchain) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->langchain) (2.1.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.7/site-packages (from aiohttp->openai) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->openai) (22.2.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.7/site-packages (from aiohttp->openai) (4.0.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.7/site-packages (from aiohttp->openai) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->openai) (1.8.2)\n",
      "Requirement already satisfied: asynctest==0.13.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->openai) (0.13.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from aiohttp->openai) (1.3.3)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from sqlalchemy->langchain) (4.11.4)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.7/site-packages (from sqlalchemy->langchain) (2.0.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->sqlalchemy->langchain) (3.11.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install langchain openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-13T15:47:24.671667Z",
     "iopub.status.busy": "2023-03-13T15:47:24.671229Z",
     "iopub.status.idle": "2023-03-13T15:47:24.678148Z",
     "shell.execute_reply": "2023-03-13T15:47:24.676794Z",
     "shell.execute_reply.started": "2023-03-13T15:47:24.671627Z"
    }
   },
   "outputs": [],
   "source": [
    "import os \n",
    "os.environ['OPENAI_API_KEY'] = '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'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-13T15:49:05.950349Z",
     "iopub.status.busy": "2023-03-13T15:49:05.949944Z",
     "iopub.status.idle": "2023-03-13T15:49:06.111977Z",
     "shell.execute_reply": "2023-03-13T15:49:06.110694Z",
     "shell.execute_reply.started": "2023-03-13T15:49:05.950312Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "llmOpen = OpenAI(temperature = 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-13T15:49:56.879994Z",
     "iopub.status.busy": "2023-03-13T15:49:56.878270Z",
     "iopub.status.idle": "2023-03-13T15:49:58.242206Z",
     "shell.execute_reply": "2023-03-13T15:49:58.240907Z",
     "shell.execute_reply.started": "2023-03-13T15:49:56.879915Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\"Data Modeling Magic: Unlocking the Secrets of AirBnB!\"\n"
     ]
    }
   ],
   "source": [
    "text = \"Provide me a catchy youtube video title for Datamodeling the AirBnB data\"\n",
    "print(llmOpen(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-13T16:16:50.840648Z",
     "iopub.status.busy": "2023-03-13T16:16:50.840187Z",
     "iopub.status.idle": "2023-03-13T16:16:50.847565Z",
     "shell.execute_reply": "2023-03-13T16:16:50.846048Z",
     "shell.execute_reply.started": "2023-03-13T16:16:50.840609Z"
    }
   },
   "outputs": [],
   "source": [
    "llmText = OpenAI(model_name='text-ada-001',n=2, best_of=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-13T16:17:25.876951Z",
     "iopub.status.busy": "2023-03-13T16:17:25.876498Z",
     "iopub.status.idle": "2023-03-13T16:17:25.898209Z",
     "shell.execute_reply": "2023-03-13T16:17:25.896239Z",
     "shell.execute_reply.started": "2023-03-13T16:17:25.876916Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generations=[[Generation(text=\"\\n\\nDatamodeling the AirBnB Data: How to Use AirBnB to Research Airports and Travel\\n\\nAirports and travel are perfect examples of how to use data to improve safety and improve the quality of life. By looking at data about airports and travel, it is easy to see how air travel can be improved and safety can be improved.\\n\\nIn order to use air travel to improve safety, it is important to understand the data. After all, air travel is vast and complex. To improve safety, it is helpful to look at data about air travel in order to understand how to improve safety.\\n\\nIn order to research air travel, it is helpful to use AirBnB. AirBnB is a platform that lets people stay in places to research air travel. After they've finished their trip, AirBnB offers people a chance to get stay in places for a short time.\\n\\nThis is a great example of how AirBnB can be used to research air travel. After finishing their trip, AirBnB offers people a chance to get stay in places for a short time. This is a great example of how AirBnB can be used to improve safety.\\n\\nIn\", generation_info={'finish_reason': 'length', 'logprobs': None}), Generation(text='\\n\\n\"Datamodeling the AirBnB Data\"', generation_info={'finish_reason': 'stop', 'logprobs': None})], [Generation(text='\\n\\nThis datamodeling journey provides a unique look at the data that is used to understand airBNB. The journey begins with understanding the \\n\\nWhat are airBNB patterns?\\n\\nThe three main airBNB patterns are CTA, DTA, and TTA. Each with its own purpose can be seen in a specific airBNB map.\\n\\nFrom the airBNB maps it is possible to see how many market access (CTA) and non-market access (DTA) markets are being used. It also begins to understand how these markets are being used and the market conditions.\\n\\nWith this information it is then able to begin to understand the airBNB patterns for a market. This can be done by creating a model that will allow for data interpretation.\\n\\nThis journey is possible due to the use of a datamodeling that helps one understand the effects of airBNB on the market conditions. This datamodeling is called the AirBnB Data Modeling Journey.', generation_info={'finish_reason': 'stop', 'logprobs': None}), Generation(text='\\n\\nThis datamodeling journey explains how a single data point can help you understand and predict patterns in the airBnB data. You will learn how to:\\n\\n1. Analyze the data\\n2. Predict the behavior\\n3. Understand the causes\\n4. liked patterns\\n5. Reduce risk\\n\\nIn this journey, you will learn how to:\\n\\n1. Understand the data\\n2. Understand the patterns\\n3. Predict the future\\n4. Reduce risk\\n5. Effectively analyze the data', generation_info={'finish_reason': 'stop', 'logprobs': None})]] llm_output={'token_usage': {'completion_tokens': 591, 'prompt_tokens': 46, 'total_tokens': 637}}\n"
     ]
    }
   ],
   "source": [
    "text1 = \"Provide me a Medium article title for Datamodeling the AirBnB data\"\n",
    "text2 = \"Provide me a 100 word youtube description for Uncovering Patterns in the AirBnB Data: A Datamodeling Journey!\"\n",
    "print(llmText.generate([text1,text2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-13T15:52:14.631377Z",
     "iopub.status.busy": "2023-03-13T15:52:14.630900Z",
     "iopub.status.idle": "2023-03-13T15:52:14.637228Z",
     "shell.execute_reply": "2023-03-13T15:52:14.636313Z",
     "shell.execute_reply.started": "2023-03-13T15:52:14.631338Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate(input_variables = [\"concept\"],\n",
    "                template=\"Provide me Youtube video title on {concept}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-13T15:53:10.320186Z",
     "iopub.status.busy": "2023-03-13T15:53:10.319775Z",
     "iopub.status.idle": "2023-03-13T15:53:10.327892Z",
     "shell.execute_reply": "2023-03-13T15:53:10.326524Z",
     "shell.execute_reply.started": "2023-03-13T15:53:10.320151Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Provide me Youtube video title on Langchain a Super Charger for LLMs\n"
     ]
    }
   ],
   "source": [
    "print(prompt.format(concept='Langchain a Super Charger for LLMs'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-13T15:55:02.526682Z",
     "iopub.status.busy": "2023-03-13T15:55:02.526252Z",
     "iopub.status.idle": "2023-03-13T15:55:03.860127Z",
     "shell.execute_reply": "2023-03-13T15:55:03.858931Z",
     "shell.execute_reply.started": "2023-03-13T15:55:02.526645Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n\"The Power of Langchain for LLM Lawyers - A Super Charger for Legal Marketers\"'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "chain_prompt = LLMChain(llm=llmOpen, prompt = prompt)\n",
    "chain_prompt.run('Langchain a Super Charger for LLMs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-13T15:56:04.701694Z",
     "iopub.status.busy": "2023-03-13T15:56:04.700858Z",
     "iopub.status.idle": "2023-03-13T15:56:18.458816Z",
     "shell.execute_reply": "2023-03-13T15:56:18.457597Z",
     "shell.execute_reply.started": "2023-03-13T15:56:04.701650Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting google-search-results\n",
      "  Downloading google_search_results-2.4.2.tar.gz (18 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: requests in /usr/lib/python3.10/site-packages (from google-search-results) (2.28.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3.10/site-packages (from requests->google-search-results) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/lib/python3.10/site-packages (from requests->google-search-results) (1.26.12)\n",
      "Building wheels for collected packages: google-search-results\n",
      "  Building wheel for google-search-results (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for google-search-results: filename=google_search_results-2.4.2-py3-none-any.whl size=32003 sha256=4306a43f6461d346c6c41f1d9c7443f213a123f1d962659613c679e973f552f2\n",
      "  Stored in directory: /home/solverbot/.cache/pip/wheels/d3/b2/c3/03302d12bb44a2cdff3c9371f31b72c0c4e84b8d2285eeac53\n",
      "Successfully built google-search-results\n",
      "Installing collected packages: google-search-results\n",
      "Successfully installed google-search-results-2.4.2\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install google-search-results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-13T16:08:41.494826Z",
     "iopub.status.busy": "2023-03-13T16:08:41.494406Z",
     "iopub.status.idle": "2023-03-13T16:08:41.501474Z",
     "shell.execute_reply": "2023-03-13T16:08:41.499615Z",
     "shell.execute_reply.started": "2023-03-13T16:08:41.494786Z"
    }
   },
   "outputs": [],
   "source": [
    "os.environ['SERPAPI_API_KEY'] = 'ef0268b23c4fa7b2630c4b07d55d55b567380317278a372fdba407e2e9a6a18a'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-13T16:13:33.337029Z",
     "iopub.status.busy": "2023-03-13T16:13:33.336530Z",
     "iopub.status.idle": "2023-03-13T16:13:33.343367Z",
     "shell.execute_reply": "2023-03-13T16:13:33.342189Z",
     "shell.execute_reply.started": "2023-03-13T16:13:33.336985Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.agents import load_tools\n",
    "from langchain.agents import initialize_agent\n",
    "from langchain.llms import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-13T16:13:47.676449Z",
     "iopub.status.busy": "2023-03-13T16:13:47.675634Z",
     "iopub.status.idle": "2023-03-13T16:13:47.702511Z",
     "shell.execute_reply": "2023-03-13T16:13:47.701189Z",
     "shell.execute_reply.started": "2023-03-13T16:13:47.676405Z"
    }
   },
   "outputs": [],
   "source": [
    "tools = load_tools([\"serpapi\",\"llm-math\"],llm=llmOpen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I should search for the movie and its cast\n",
      "Action: Search\n",
      "Action Input: Indian movie won Oscar\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mIndia has made movie history by scooping its first Oscar for the best original song, “Naatu Naatu.” Praised for its buoyant choreography and catchy tune, the song, which has already won a Golden Globe award, is from the movie “RRR,” a Telugu-language drama set during India's struggle for independence from Britain.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I should look up the cast of the movie\n",
      "Action: Search\n",
      "Action Input: Cast of RRR\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mA tale of two legendary revolutionaries and their journey far away from home. After their journey they return home to start fighting back against British colonialists in the 1920s.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I should look up the cast of the movie\n",
      "Action: Search\n",
      "Action Input: Cast of RRR\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mA tale of two legendary revolutionaries and their journey far away from home. After their journey they return home to start fighting back against British colonialists in the 1920s.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the cast of the movie\n",
      "Final Answer: The movie RRR has recently won Oscar. The cast of the movie includes Ram Charan, Jr. NTR, Alia Bhatt, Ajay Devgn, Olivia Morris, Samuthirakani, Ray Stevenson and Alison Doody.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The movie RRR has recently won Oscar. The cast of the movie includes Ram Charan, Jr. NTR, Alia Bhatt, Ajay Devgn, Olivia Morris, Samuthirakani, Ray Stevenson and Alison Doody.'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent = initialize_agent(tools, llmOpen, \n",
    "                         agent='zero-shot-react-description',\n",
    "                        verbose=True)\n",
    "agent.run(\"\"\"Which Indian movie has recently won Oscar. Who are the \n",
    "          actions in the film\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: I need the Steps to\n",
      "            Digital Market youtube videos \n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' Sure, I can help you with that. The steps to digital market YouTube videos are as follows: \\n1. Create a YouTube channel and upload your videos. \\n2. Optimize your videos for SEO by including relevant keywords in the title, description, and tags. \\n3. Promote your videos on social media platforms such as Facebook, Twitter, and Instagram. \\n4. Use YouTube Ads to reach a wider audience. \\n5. Monitor your analytics to track the performance of your videos. \\n6. Engage with your viewers by responding to comments and creating playlists. \\n7. Collaborate with other YouTubers to cross-promote your videos. \\n8. Leverage influencers to promote your videos. \\nI hope this helps!'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain import OpenAI, ConversationChain\n",
    "\n",
    "llm = OpenAI(temperature=0)\n",
    "conversation = ConversationChain(llm=llm, verbose=True)\n",
    "\n",
    "conversation.predict(input=\"\"\"I need the Steps to\n",
    "            Digital Market youtube videos \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: I need the Steps to\n",
      "            Digital Market youtube videos \n",
      "AI:  Sure, I can help you with that. The steps to digital market YouTube videos are as follows: \n",
      "1. Create a YouTube channel and upload your videos. \n",
      "2. Optimize your videos for SEO by including relevant keywords in the title, description, and tags. \n",
      "3. Promote your videos on social media platforms such as Facebook, Twitter, and Instagram. \n",
      "4. Use YouTube Ads to reach a wider audience. \n",
      "5. Monitor your analytics to track the performance of your videos. \n",
      "6. Engage with your viewers by responding to comments and creating playlists. \n",
      "7. Collaborate with other YouTubers to cross-promote your videos. \n",
      "8. Leverage influencers to promote your videos. \n",
      "I hope this helps!\n",
      "Human: That helped. Can you explain more \n",
      "on the Leveraging Influencers?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' Absolutely! Leveraging influencers is a great way to promote your videos and reach a wider audience. You can reach out to influencers in your niche and ask them to share your videos with their followers. You can also collaborate with them on content or offer them incentives to promote your videos. This can help you reach a larger audience and increase your views and subscribers.'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"\"\"That helped. Can you explain more \n",
    "on the Leveraging Influencers?\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "shutil.unpack_archive(\"archive.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain import OpenAI, VectorDBQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import TextLoader,CSVLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "textload = TextLoader('resume_notes.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "textDoc = textload.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(textDoc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 1301, which is longer than the specified 1000\n",
      "Created a chunk of size 1012, which is longer than the specified 1000\n"
     ]
    }
   ],
   "source": [
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "texts = text_splitter.split_documents(textDoc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting chromadb\n",
      "  Downloading chromadb-0.3.11-py3-none-any.whl (41 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.4/41.4 kB\u001b[0m \u001b[31m138.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hCollecting clickhouse-connect>=0.5.7\n",
      "  Downloading clickhouse_connect-0.5.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (922 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m922.5/922.5 kB\u001b[0m \u001b[31m249.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: uvicorn[standard]>=0.18.3 in /home/solverbot/.local/lib/python3.10/site-packages (from chromadb) (0.20.0)\n",
      "Collecting sentence-transformers>=2.2.2\n",
      "  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m437.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: fastapi>=0.85.1 in /home/solverbot/.local/lib/python3.10/site-packages (from chromadb) (0.89.1)\n",
      "Requirement already satisfied: duckdb>=0.5.1 in /home/solverbot/.local/lib/python3.10/site-packages (from chromadb) (0.6.1)\n",
      "Requirement already satisfied: pydantic>=1.9 in /usr/lib/python3.10/site-packages (from chromadb) (1.10.4)\n",
      "Requirement already satisfied: pandas>=1.3 in /home/solverbot/.local/lib/python3.10/site-packages (from chromadb) (1.5.1)\n",
      "Collecting hnswlib>=0.7\n",
      "  Downloading hnswlib-0.7.0.tar.gz (33 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.21.6 in /home/solverbot/.local/lib/python3.10/site-packages (from chromadb) (1.23.4)\n",
      "Requirement already satisfied: requests>=2.28 in /usr/lib/python3.10/site-packages (from chromadb) (2.28.1)\n",
      "Requirement already satisfied: pytz in /usr/lib/python3.10/site-packages (from clickhouse-connect>=0.5.7->chromadb) (2022.7)\n",
      "Requirement already satisfied: certifi in /usr/lib/python3.10/site-packages (from clickhouse-connect>=0.5.7->chromadb) (2022.12.7)\n",
      "Requirement already satisfied: urllib3>=1.26 in /usr/lib/python3.10/site-packages (from clickhouse-connect>=0.5.7->chromadb) (1.26.12)\n",
      "Collecting zstandard\n",
      "  Downloading zstandard-0.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.6 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m341.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting lz4\n",
      "  Downloading lz4-4.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m460.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: starlette==0.22.0 in /home/solverbot/.local/lib/python3.10/site-packages (from fastapi>=0.85.1->chromadb) (0.22.0)\n",
      "Requirement already satisfied: anyio<5,>=3.4.0 in /usr/lib/python3.10/site-packages (from starlette==0.22.0->fastapi>=0.85.1->chromadb) (3.6.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/lib/python3.10/site-packages (from pandas>=1.3->chromadb) (2.8.2)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/lib/python3.10/site-packages (from pydantic>=1.9->chromadb) (4.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3.10/site-packages (from requests>=2.28->chromadb) (3.4)\n",
      "Collecting transformers<5.0.0,>=4.6.0\n",
      "  Using cached transformers-4.26.1-py3-none-any.whl (6.3 MB)\n",
      "Requirement already satisfied: tqdm in /home/solverbot/.local/lib/python3.10/site-packages (from sentence-transformers>=2.2.2->chromadb) (4.64.1)\n",
      "Collecting torch>=1.6.0\n",
      "  Downloading torch-1.13.1-cp310-cp310-manylinux1_x86_64.whl (887.5 MB)\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.2/887.5 MB\u001b[0m \u001b[31m457.5 kB/s\u001b[0m eta \u001b[36m0:29:43\u001b[0m:00\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Could not import chromadb python package. Please install it with `pip install chromadb`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/langchain/vectorstores/chroma.py:62\u001b[0m, in \u001b[0;36mChroma.__init__\u001b[0;34m(self, collection_name, embedding_function, persist_directory, client_settings)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 62\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mchromadb\u001b[39;00m\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mchromadb\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'chromadb'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m OpenAIEmbeddings()\n\u001b[0;32m----> 2\u001b[0m docsearch \u001b[38;5;241m=\u001b[39m \u001b[43mChroma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresume_texts\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/langchain/vectorstores/chroma.py:265\u001b[0m, in \u001b[0;36mChroma.from_documents\u001b[0;34m(cls, documents, embedding, ids, collection_name, persist_directory, client_settings, **kwargs)\u001b[0m\n\u001b[1;32m    263\u001b[0m texts \u001b[38;5;241m=\u001b[39m [doc\u001b[38;5;241m.\u001b[39mpage_content \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[1;32m    264\u001b[0m metadatas \u001b[38;5;241m=\u001b[39m [doc\u001b[38;5;241m.\u001b[39mmetadata \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[0;32m--> 265\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_texts\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    266\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtexts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollection_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpersist_directory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpersist_directory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient_settings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient_settings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/langchain/vectorstores/chroma.py:228\u001b[0m, in \u001b[0;36mChroma.from_texts\u001b[0;34m(cls, texts, embedding, metadatas, ids, collection_name, persist_directory, client_settings, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_texts\u001b[39m(\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    210\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Chroma:\n\u001b[1;32m    211\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Create a Chroma vectorstore from a raw documents.\u001b[39;00m\n\u001b[1;32m    212\u001b[0m \n\u001b[1;32m    213\u001b[0m \u001b[38;5;124;03m    If a persist_directory is specified, the collection will be persisted there.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;124;03m        Chroma: Chroma vectorstore.\u001b[39;00m\n\u001b[1;32m    227\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 228\u001b[0m     chroma_collection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    229\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollection_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    230\u001b[0m \u001b[43m        \u001b[49m\u001b[43membedding_function\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    231\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpersist_directory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpersist_directory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    232\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclient_settings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient_settings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    233\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    234\u001b[0m     chroma_collection\u001b[38;5;241m.\u001b[39madd_texts(texts\u001b[38;5;241m=\u001b[39mtexts, metadatas\u001b[38;5;241m=\u001b[39mmetadatas, ids\u001b[38;5;241m=\u001b[39mids)\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m chroma_collection\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/langchain/vectorstores/chroma.py:65\u001b[0m, in \u001b[0;36mChroma.__init__\u001b[0;34m(self, collection_name, embedding_function, persist_directory, client_settings)\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mchromadb\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     66\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not import chromadb python package. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     67\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease install it with `pip install chromadb`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     68\u001b[0m     )\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m client_settings:\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client_settings \u001b[38;5;241m=\u001b[39m client_settings\n",
      "\u001b[0;31mValueError\u001b[0m: Could not import chromadb python package. Please install it with `pip install chromadb`."
     ]
    }
   ],
   "source": [
    "embeddings = OpenAIEmbeddings()\n",
    "docsearch = Chroma.from_documents(texts, embeddings, collection_name=\"resume_texts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
